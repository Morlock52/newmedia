# Network Optimization for 10Gbps+ Performance
# System-wide network tuning for ultra-high bandwidth media streaming

# This configuration should be applied to /etc/sysctl.d/99-media-server-network.conf

# Core Network Settings
# ====================

# Increase Linux autotuning TCP buffer limits
# Min, default, and max bytes
net.ipv4.tcp_rmem = 4096 1048576 134217728
net.ipv4.tcp_wmem = 4096 1048576 134217728

# Increase the maximum socket receive buffer
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728

# Increase default socket buffer sizes
net.core.rmem_default = 1048576
net.core.wmem_default = 1048576

# Increase maximum backlog
net.core.netdev_max_backlog = 30000
net.ipv4.tcp_max_syn_backlog = 30000

# Increase the maximum number of packets queued
net.core.netdev_budget = 600
net.core.netdev_budget_usecs = 8000

# TCP Performance Tuning
# ======================

# Enable TCP Fast Open (TFO)
net.ipv4.tcp_fastopen = 3

# Enable TCP MTU Probing
net.ipv4.tcp_mtu_probing = 1
net.ipv4.tcp_base_mss = 1024

# Disable TCP slow start after idle
net.ipv4.tcp_slow_start_after_idle = 0

# Enable BBR congestion control (requires kernel 4.9+)
net.core.default_qdisc = fq
net.ipv4.tcp_congestion_control = bbr

# Optimize TCP keepalive
net.ipv4.tcp_keepalive_time = 300
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 5

# Enable window scaling
net.ipv4.tcp_window_scaling = 1

# Enable timestamps
net.ipv4.tcp_timestamps = 1

# Enable selective acknowledgments
net.ipv4.tcp_sack = 1
net.ipv4.tcp_dsack = 1
net.ipv4.tcp_fack = 1

# Increase the TCP FIN timeout
net.ipv4.tcp_fin_timeout = 15

# Reuse TIME_WAIT sockets
net.ipv4.tcp_tw_reuse = 1

# Increase number of simultaneous connections
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_max_tw_buckets = 2000000

# UDP Optimizations
# =================

# Increase UDP buffer sizes for streaming
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728
net.ipv4.udp_rmem_min = 8192
net.ipv4.udp_wmem_min = 8192

# Network Interface Optimizations
# ===============================

# Increase netdev budget for packet processing
net.core.netdev_budget = 600

# Enable RPS (Receive Packet Steering)
net.core.rps_sock_flow_entries = 32768

# Increase the maximum number of connections tracked
net.netfilter.nf_conntrack_max = 2000000
net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 86400

# Memory and VM Tuning
# ====================

# Increase system file descriptor limit
fs.file-max = 2097152

# Allow more aggressive network memory usage
vm.min_free_kbytes = 1048576
vm.swappiness = 0

# Security and DDOS Protection
# ============================

# Enable SYN cookies
net.ipv4.tcp_syncookies = 1

# Protect against SYN flood attacks
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_syn_retries = 2

# Enable IP spoofing protection
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.rp_filter = 1

# Disable ICMP redirects
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.all.send_redirects = 0

# Jumbo Frames Support
# ====================

# Note: Also requires configuration at the network interface level
# Add to /etc/network/interfaces or NetworkManager:
# mtu 9000

# IPv6 Optimizations
# ==================

# Enable IPv6
net.ipv6.conf.all.disable_ipv6 = 0
net.ipv6.conf.default.disable_ipv6 = 0

# IPv6 buffer sizes
net.ipv6.tcp_rmem = 4096 1048576 134217728
net.ipv6.tcp_wmem = 4096 1048576 134217728

# Additional Performance Settings
# ===============================

# Increase the maximum number of orphaned sockets
net.ipv4.tcp_max_orphans = 262144

# Increase max number of sockets in TIME_WAIT
net.ipv4.tcp_max_tw_buckets = 2000000

# Enable TCP ECN
net.ipv4.tcp_ecn = 2

# Optimize for low latency
net.ipv4.tcp_low_latency = 1

# Network Interface Ring Buffer Settings
# ======================================
# Apply with ethtool (add to network startup scripts):
#
# ethtool -G eth0 rx 4096 tx 4096
# ethtool -K eth0 gro on gso on tso on
# ethtool -C eth0 adaptive-rx on adaptive-tx on
# ethtool -C eth0 rx-usecs 100 tx-usecs 100

# IRQ Affinity Settings
# =====================
# Distribute network interrupts across CPU cores
# Add to /etc/rc.local or systemd service:
#
# # Set IRQ affinity for network interfaces
# for irq in $(grep eth0 /proc/interrupts | awk '{print $1}' | sed 's/://g'); do
#     echo 4 > /proc/irq/$irq/smp_affinity
# done

# NIC Offloading Features
# =======================
# Enable hardware offloading (add to network startup):
#
# ethtool -K eth0 rx-checksumming on
# ethtool -K eth0 tx-checksumming on
# ethtool -K eth0 scatter-gather on
# ethtool -K eth0 tcp-segmentation-offload on
# ethtool -K eth0 generic-segmentation-offload on
# ethtool -K eth0 generic-receive-offload on
# ethtool -K eth0 large-receive-offload on
# ethtool -K eth0 rx-vlan-offload on
# ethtool -K eth0 tx-vlan-offload on
# ethtool -K eth0 ntuple on
# ethtool -K eth0 rx-hashing on

# CPU Performance Governor
# ========================
# Set CPU to performance mode for consistent network performance
# Add to /etc/rc.local:
#
# for cpu in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do
#     echo performance > $cpu
# done

# NUMA Optimizations
# ==================
# For NUMA systems, bind network interrupts to local NUMA node
# Check NUMA topology: numactl --hardware
#
# Example for binding to NUMA node 0:
# echo 0 > /sys/class/net/eth0/device/numa_node